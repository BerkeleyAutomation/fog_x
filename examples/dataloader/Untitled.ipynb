{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "608ae1bd-0b68-4e0e-b748-e7f89807724e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fog_x \n",
    "import os\n",
    "from logging import getLogger\n",
    "import numpy as np\n",
    "\n",
    "class BaseLoader():\n",
    "    def __init__(self, data_path):\n",
    "        super(BaseLoader, self).__init__()\n",
    "        self.data_dir = data_path\n",
    "        self.logger = getLogger(__name__)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __iter___(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "class RTXLoader(BaseLoader):\n",
    "    def __init__(self, data_path, split = 'train[:50]'):\n",
    "        super(RTXLoader, self).__init__(data_path)\n",
    "        import tensorflow_datasets as tfds\n",
    "\n",
    "        builder = tfds.builder_from_directory(data_path)\n",
    "\n",
    "        self.ds = builder.as_dataset(split=split)\n",
    "        # https://www.determined.ai/blog/tf-dataset-the-bad-parts\n",
    "        # data_source = builder.as_data_source()\n",
    "        # print(data_source)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return idx\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self.ds.__iter__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fbcb3e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I 2024-06-22 09:48:48,542 dataset_info.py:617] Load dataset info from /home/kych/datasets/berkeley_autolab_ur5/0.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I 2024-06-22 09:48:48,598 reader.py:261] Creating a tf.data.Dataset reading 2 files located in folders: /home/kych/datasets/berkeley_autolab_ur5/0.1.0.\n",
      "I 2024-06-22 09:48:48,646 logging_logger.py:49] Constructing tf.data.Dataset berkeley_autolab_ur5 for split train[:5], from /home/kych/datasets/berkeley_autolab_ur5/0.1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = RTXLoader(os.path.expanduser(\"~/datasets/berkeley_autolab_ur5/0.1.0\"), split = 'train[:5]')\n",
    "# RTXLoader(\"gs://gresearch/robotics/berkeley_autolab_ur5/0.1.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fe6f0124-e66c-4529-8354-12fbc0769de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BaseExporter():\n",
    "    def __init__(self):\n",
    "        super(BaseExporter, self).__init__()\n",
    "        self.logger = getLogger(__name__)\n",
    "\n",
    "    def export(self, loader: BaseLoader, output_path: str):\n",
    "        raise NotImplementedError\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9920acb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-22 09:57:32.410997: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-22 09:57:33.193706: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-22 09:57:34.034370: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-22 09:57:34.866546: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-22 09:57:36.165707: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-22 09:57:36.169930: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "import av\n",
    "import pickle \n",
    "\n",
    "class MKVExporter(BaseExporter):\n",
    "    def __init__(self):\n",
    "        super(MKVExporter, self).__init__()\n",
    "\n",
    "    # Function to create a frame from numpy array\n",
    "    def create_frame(self, image_array, stream):\n",
    "        frame = av.VideoFrame.from_ndarray(np.array(image_array), format='rgb24')\n",
    "        frame.pict_type = 'NONE'\n",
    "        frame.time_base = stream.time_base\n",
    "        return frame\n",
    "    \n",
    "    # Function to create a frame from numpy array\n",
    "    def create_frame_depth(self, image_array, stream):\n",
    "        image_array = np.array(image_array)\n",
    "        # if float, convert to uint8\n",
    "        if image_array.dtype == np.float32:\n",
    "            image_array = (image_array * 255).astype(np.uint8)\n",
    "        # if 3 dim, convert to 2 dim\n",
    "        if len(image_array.shape) == 3:\n",
    "            image_array = image_array[:,:,0]\n",
    "        frame = av.VideoFrame.from_ndarray(image_array, format='gray')\n",
    "        frame.pict_type = 'NONE'\n",
    "        frame.time_base = stream.time_base\n",
    "        return frame\n",
    "\n",
    "    def export(self, loader: BaseLoader, output_path: str):\n",
    "        # Create an output container\n",
    "        i = -1\n",
    "        for traj_tensor in loader:\n",
    "            i += 1\n",
    "            trajectory = dict(traj_tensor)\n",
    "            output = av.open(f'{output_path}/output_{i}.mkv', mode='w')\n",
    "            # Define video streams (assuming images are 640x480 RGB)\n",
    "            video_stream_1 = output.add_stream('libx264', rate=10)\n",
    "            video_stream_1.width = 640\n",
    "            video_stream_1.height = 480\n",
    "            video_stream_1.pix_fmt = 'yuv420p'\n",
    "\n",
    "            video_stream_2 = output.add_stream('libx264', rate=1)\n",
    "            video_stream_2.width = 640\n",
    "            video_stream_2.height = 480\n",
    "            video_stream_2.pix_fmt = 'yuv420p'\n",
    "\n",
    "            # Define custom data stream for vectors\n",
    "            depth_stream = output.add_stream('libx264', rate=1)\n",
    "\n",
    "            data_stream = output.add_stream('rawvideo', rate=1)\n",
    "\n",
    "            ts = 0\n",
    "            # convert step data to stream\n",
    "            for step_tensor in trajectory[\"steps\"]:\n",
    "                step = dict(step_tensor)\n",
    "                # non_image_data_step = dict(step_tensor)\n",
    "                # non_image_data_step[\"observation\"].pop(\"image\")\n",
    "                # non_image_data_step[\"observation\"].pop(\"hand_image\")\n",
    "                # non_image_data_step[\"observation\"].pop(\"image_with_depth\")\n",
    "                # non_image_data_bytes = str(non_image_data_step).encode()\n",
    "                # print(step)\n",
    "                obesrvation = step_tensor[\"observation\"].copy()\n",
    "                obesrvation.pop(\"image\")\n",
    "                obesrvation.pop(\"hand_image\")\n",
    "                obesrvation.pop(\"image_with_depth\")\n",
    "                non_image_data_step = step.copy()\n",
    "                non_image_data_step[\"observation\"] = obesrvation\n",
    "\n",
    "                non_image_data_bytes = pickle.dumps(non_image_data_step)\n",
    "                packet = av.Packet(non_image_data_bytes)\n",
    "                packet.stream = data_stream\n",
    "                packet.pts = ts\n",
    "                output.mux(packet)\n",
    "\n",
    "\n",
    "                image =np.array(step[\"observation\"][\"image\"])\n",
    "                # Create a frame from the numpy array\n",
    "                frame = self.create_frame(image, video_stream_1)\n",
    "                frame.pts = ts\n",
    "                packet = video_stream_1.encode(frame)\n",
    "                \n",
    "                output.mux(packet)\n",
    "\n",
    "                hand_image =np.array(step[\"observation\"][\"hand_image\"])\n",
    "                # Create a frame from the numpy array\n",
    "                frame = self.create_frame(hand_image, video_stream_2)\n",
    "                frame.pts = ts\n",
    "                packet = video_stream_2.encode(frame)\n",
    "                output.mux(packet)\n",
    "\n",
    "                # # Create a frame from the numpy array\n",
    "                frame = self.create_frame_depth(step[\"observation\"][\"image_with_depth\"], depth_stream)\n",
    "                # frame.pts = ts\n",
    "                # Encode the frame\n",
    "                packet = depth_stream.encode(frame)\n",
    "                # Write the packet to the output file\n",
    "                output.mux(packet)\n",
    "\n",
    "                ts += 1\n",
    "\n",
    "\n",
    "\n",
    "            output.close()\n",
    "            print(ts)\n",
    "\n",
    "\n",
    "exporter = MKVExporter()\n",
    "output_path = os.path.expanduser(\"~\") + \"/fog_x/examples/dataloader/mkv_output/\"\n",
    "exporter.export(dataset,output_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9b27ac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MKVLoader(BaseLoader):\n",
    "    def __init__(self, data_path):\n",
    "        super(MKVLoader, self).__init__(data_path)\n",
    "        self.files = os.listdir(data_path)\n",
    "        self.index = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return idx\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.index < len(self.files):\n",
    "            result = self.files[self.index]\n",
    "            self.index += 1\n",
    "            return result\n",
    "        else:\n",
    "            raise StopIteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "80867561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[<av.VideoFrame #0, pts=0 yuv420p 640x480 at 0x7d4229d85070>]\n",
      "[<av.VideoFrame #1, pts=0 yuv420p 640x480 at 0x7d4204986420>]\n",
      "[<av.VideoFrame #2, pts=0 yuv420p 640x480 at 0x7d4229d87530>]\n",
      "[<av.VideoFrame #3, pts=0 yuv420p 640x480 at 0x7d4204986500>]\n",
      "[<av.VideoFrame #4, pts=0 yuv420p 640x480 at 0x7d4204986490>]\n",
      "[<av.VideoFrame #5, pts=0 yuv420p 640x480 at 0x7d41ccf63ae0>]\n",
      "[<av.VideoFrame #6, pts=0 yuv420p 640x480 at 0x7d41ccf611c0>]\n",
      "[<av.VideoFrame #7, pts=0 yuv420p 640x480 at 0x7d420495fca0>]\n",
      "[<av.VideoFrame #8, pts=0 yuv420p 640x480 at 0x7d420495f7d0>]\n",
      "[<av.VideoFrame #9, pts=0 yuv420p 640x480 at 0x7d421023a490>]\n",
      "[<av.VideoFrame #10, pts=0 yuv420p 640x480 at 0x7d4210239230>]\n",
      "[<av.VideoFrame #11, pts=0 yuv420p 640x480 at 0x7d421023ae30>]\n",
      "[<av.VideoFrame #12, pts=0 yuv420p 640x480 at 0x7d421023ac70>]\n",
      "[<av.VideoFrame #13, pts=0 yuv420p 640x480 at 0x7d421003f450>]\n",
      "[<av.VideoFrame #14, pts=0 yuv420p 640x480 at 0x7d421003de70>]\n",
      "[<av.VideoFrame #15, pts=0 yuv420p 640x480 at 0x7d421003e500>]\n",
      "[<av.VideoFrame #16, pts=0 yuv420p 640x480 at 0x7d421003e490>]\n",
      "[<av.VideoFrame #17, pts=0 yuv420p 640x480 at 0x7d421003e960>]\n",
      "[<av.VideoFrame #18, pts=0 yuv420p 640x480 at 0x7d421003e810>]\n",
      "[<av.VideoFrame #19, pts=0 yuv420p 640x480 at 0x7d421003f4c0>]\n",
      "[<av.VideoFrame #20, pts=0 yuv420p 640x480 at 0x7d421003e9d0>]\n",
      "[<av.VideoFrame #21, pts=0 yuv420p 640x480 at 0x7d421003e8f0>]\n",
      "[<av.VideoFrame #22, pts=0 yuv420p 640x480 at 0x7d421003eb20>]\n",
      "[<av.VideoFrame #23, pts=0 yuv420p 640x480 at 0x7d421003c3c0>]\n",
      "[<av.VideoFrame #24, pts=0 yuv420p 640x480 at 0x7d421003df50>]\n",
      "[<av.VideoFrame #25, pts=0 yuv420p 640x480 at 0x7d421003eb90>]\n",
      "[<av.VideoFrame #26, pts=0 yuv420p 640x480 at 0x7d421003ec00>]\n",
      "[<av.VideoFrame #27, pts=0 yuv420p 640x480 at 0x7d421003dc40>]\n",
      "[<av.VideoFrame #28, pts=0 yuv420p 640x480 at 0x7d421003f3e0>]\n",
      "[<av.VideoFrame #29, pts=0 yuv420p 640x480 at 0x7d421003f300>]\n",
      "[<av.VideoFrame #30, pts=0 yuv420p 640x480 at 0x7d421003dee0>]\n",
      "[<av.VideoFrame #31, pts=0 yuv420p 640x480 at 0x7d421003dd20>]\n",
      "[<av.VideoFrame #32, pts=0 yuv420p 640x480 at 0x7d421003db60>]\n",
      "[<av.VideoFrame #33, pts=0 yuv420p 640x480 at 0x7d421003fed0>]\n",
      "[<av.VideoFrame #34, pts=0 yuv420p 640x480 at 0x7d421003f610>]\n",
      "[<av.VideoFrame #35, pts=0 yuv420p 640x480 at 0x7d421003f5a0>]\n",
      "[<av.VideoFrame #36, pts=0 yuv420p 640x480 at 0x7d421003f680>]\n",
      "[<av.VideoFrame #37, pts=0 yuv420p 640x480 at 0x7d421003f6f0>]\n",
      "[]\n",
      "[]\n",
      "[<av.VideoFrame #0, pts=0 yuv420p 640x480 at 0x7d421003e3b0>]\n",
      "[<av.VideoFrame #1, pts=0 yuv420p 640x480 at 0x7d421003e1f0>]\n",
      "[<av.VideoFrame #2, pts=0 yuv420p 640x480 at 0x7d421011ccf0>]\n",
      "[<av.VideoFrame #3, pts=0 yuv420p 640x480 at 0x7d421011c350>]\n",
      "[<av.VideoFrame #4, pts=0 yuv420p 640x480 at 0x7d421011f0d0>]\n",
      "[<av.VideoFrame #5, pts=0 yuv420p 640x480 at 0x7d421011cc10>]\n",
      "[<av.VideoFrame #6, pts=0 yuv420p 640x480 at 0x7d421011d070>]\n",
      "[<av.VideoFrame #7, pts=0 yuv420p 640x480 at 0x7d421011c2e0>]\n",
      "[<av.VideoFrame #8, pts=0 yuv420p 640x480 at 0x7d421011e6c0>]\n",
      "[<av.VideoFrame #9, pts=0 yuv420p 640x480 at 0x7d421011edc0>]\n",
      "[<av.VideoFrame #10, pts=0 yuv420p 640x480 at 0x7d421011e880>]\n",
      "[<av.VideoFrame #11, pts=0 yuv420p 640x480 at 0x7d421011e7a0>]\n",
      "[<av.VideoFrame #12, pts=0 yuv420p 640x480 at 0x7d421011d7e0>]\n",
      "[<av.VideoFrame #13, pts=0 yuv420p 640x480 at 0x7d421011d770>]\n",
      "[<av.VideoFrame #14, pts=0 yuv420p 640x480 at 0x7d421011de00>]\n",
      "[<av.VideoFrame #15, pts=0 yuv420p 640x480 at 0x7d421011cd60>]\n",
      "[<av.VideoFrame #16, pts=0 yuv420p 640x480 at 0x7d41ccf9a650>]\n",
      "[<av.VideoFrame #17, pts=0 yuv420p 640x480 at 0x7d41ccf99230>]\n",
      "[<av.VideoFrame #18, pts=0 yuv420p 640x480 at 0x7d41ccf990e0>]\n",
      "[<av.VideoFrame #19, pts=0 yuv420p 640x480 at 0x7d41ccf9a730>]\n",
      "[<av.VideoFrame #20, pts=0 yuv420p 640x480 at 0x7d41ccf9a8f0>]\n",
      "[<av.VideoFrame #21, pts=0 yuv420p 640x480 at 0x7d41ccf992a0>]\n",
      "[<av.VideoFrame #22, pts=0 yuv420p 640x480 at 0x7d41ccf993f0>]\n",
      "[<av.VideoFrame #23, pts=0 yuv420p 640x480 at 0x7d41ccf99460>]\n",
      "[<av.VideoFrame #24, pts=0 yuv420p 640x480 at 0x7d41ccf99a10>]\n",
      "[<av.VideoFrame #25, pts=0 yuv420p 640x480 at 0x7d41ccf994d0>]\n",
      "[<av.VideoFrame #26, pts=0 yuv420p 640x480 at 0x7d41ccf99af0>]\n",
      "[<av.VideoFrame #27, pts=0 yuv420p 640x480 at 0x7d41ccf999a0>]\n",
      "[<av.VideoFrame #28, pts=0 yuv420p 640x480 at 0x7d41ccf99700>]\n",
      "[<av.VideoFrame #29, pts=0 yuv420p 640x480 at 0x7d41ccf99b60>]\n",
      "[<av.VideoFrame #30, pts=0 yuv420p 640x480 at 0x7d41ccf99a80>]\n",
      "[<av.VideoFrame #31, pts=0 yuv420p 640x480 at 0x7d41ccf99cb0>]\n",
      "[<av.VideoFrame #32, pts=0 yuv420p 640x480 at 0x7d41ccf99d20>]\n",
      "[<av.VideoFrame #33, pts=0 yuv420p 640x480 at 0x7d41ccf99c40>]\n",
      "[<av.VideoFrame #34, pts=0 yuv420p 640x480 at 0x7d41ccf99d90>]\n",
      "[<av.VideoFrame #35, pts=0 yuv420p 640x480 at 0x7d41ccf99e70>]\n",
      "[<av.VideoFrame #36, pts=0 yuv420p 640x480 at 0x7d41ccf99ee0>]\n",
      "[<av.VideoFrame #37, pts=0 yuv420p 640x480 at 0x7d41ccf99e00>]\n",
      "[<av.VideoFrame #39, pts=0 yuv420p 640x480 at 0x7d421003e420>, <av.VideoFrame #39, pts=0 yuv420p 640x480 at 0x7d420bf2c970>]\n",
      "[<av.VideoFrame #39, pts=0 yuv420p 640x480 at 0x7d41ccf99f50>, <av.VideoFrame #39, pts=0 yuv420p 640x480 at 0x7d420bf2d850>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(205, 40, 40, 40, 81)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_container = av.open(\"./mkv_output/output_2.mkv\")\n",
    "video_stream1 = input_container.streams.video[0] \n",
    "video_stream2 = input_container.streams.video[1] \n",
    "depth_stream = input_container.streams.video[2] \n",
    "data_stream = input_container.streams[3] \n",
    "\n",
    "decoded_stream_1 = []\n",
    "decoded_stream_2 = []\n",
    "decoded_stream_depth = []\n",
    "decoded_stream_data = []\n",
    "\n",
    "pkt_counter = 0\n",
    "for packet in input_container.demux(video_stream1, video_stream2, depth_stream, data_stream):\n",
    "    pkt_counter += 1\n",
    "    if packet.stream.index == video_stream1.index: \n",
    "        frame = packet.decode()\n",
    "        print(frame)\n",
    "        if frame:\n",
    "            for f in frame:\n",
    "                image = f.to_ndarray(format='rgb24')\n",
    "                decoded_stream_1.append(image)\n",
    "    elif packet.stream.index == video_stream2.index:\n",
    "        frame = packet.decode()\n",
    "        print(frame)\n",
    "        if frame:\n",
    "            for f in frame:\n",
    "                image = f.to_ndarray(format='rgb24')\n",
    "                decoded_stream_2.append(image)\n",
    "    elif packet.stream.index == depth_stream.index:\n",
    "        frame = packet.decode()\n",
    "        if frame:\n",
    "            for f in frame:\n",
    "                image = f.to_ndarray(format='gray')\n",
    "                decoded_stream_depth.append(image)\n",
    "    elif packet.stream.index == data_stream.index:\n",
    "        packet_in_bytes = bytes(packet)\n",
    "        if packet_in_bytes:\n",
    "            non_dict = pickle.loads(packet_in_bytes)\n",
    "            decoded_stream_data.append(non_dict)\n",
    "    else:\n",
    "        print(\"Unknown stream\")\n",
    "        \n",
    "input_container.close()\n",
    "\n",
    "pkt_counter, len(decoded_stream_1), len(decoded_stream_2), len(decoded_stream_depth), len(decoded_stream_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcfc1bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<av.VideoStream #0 h264, yuv420p 640x480 at 0x7d4229e588e0>,\n",
       " <av.VideoStream #1 h264, yuv420p 640x480 at 0x7d4229e58040>,\n",
       " <av.VideoStream #2 h264, yuv420p 640x480 at 0x7d4229e5abc0>,\n",
       " <av.VideoStream #3 rawvideo, yuv420p 640x480 at 0x7d4229e58fa0>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(input_container.streams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0822a45a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
