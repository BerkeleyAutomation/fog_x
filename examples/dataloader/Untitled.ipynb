{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "608ae1bd-0b68-4e0e-b748-e7f89807724e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fog_x \n",
    "import os\n",
    "from logging import getLogger\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}\n",
    "import tensorflow as tf\n",
    "\n",
    "class BaseLoader():\n",
    "    def __init__(self, data_path):\n",
    "        super(BaseLoader, self).__init__()\n",
    "        self.data_dir = data_path\n",
    "        self.logger = getLogger(__name__)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __iter___(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "class RTXLoader(BaseLoader):\n",
    "    def __init__(self, data_path, split = 'train[:50]'):\n",
    "        super(RTXLoader, self).__init__(data_path)\n",
    "        import tensorflow_datasets as tfds\n",
    "\n",
    "        builder = tfds.builder_from_directory(data_path)\n",
    "\n",
    "        self.ds = builder.as_dataset(split=split)\n",
    "        # https://www.determined.ai/blog/tf-dataset-the-bad-parts\n",
    "        # data_source = builder.as_data_source()\n",
    "        # print(data_source)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return idx\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self.ds.__iter__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe6f0124-e66c-4529-8354-12fbc0769de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BaseExporter():\n",
    "    def __init__(self):\n",
    "        super(BaseExporter, self).__init__()\n",
    "        self.logger = getLogger(__name__)\n",
    "\n",
    "    def export(self, loader: BaseLoader, output_path: str):\n",
    "        raise NotImplementedError\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9920acb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import av\n",
    "import pickle \n",
    "\n",
    "class MKVExporter(BaseExporter):\n",
    "    def __init__(self):\n",
    "        super(MKVExporter, self).__init__()\n",
    "\n",
    "    # Function to create a frame from numpy array\n",
    "    def create_frame(self, image_array, stream):\n",
    "        frame = av.VideoFrame.from_ndarray(np.array(image_array), format='rgb24')\n",
    "        frame.pict_type = 'NONE'\n",
    "        frame.time_base = stream.time_base\n",
    "        return frame\n",
    "    \n",
    "    # Function to create a frame from numpy array\n",
    "    def create_frame_depth(self, image_array, stream):\n",
    "        image_array = np.array(image_array)\n",
    "        # if float, convert to uint8\n",
    "        if image_array.dtype == np.float32:\n",
    "            image_array = (image_array * 255).astype(np.uint8)\n",
    "        # if 3 dim, convert to 2 dim\n",
    "        if len(image_array.shape) == 3:\n",
    "            image_array = image_array[:,:,0]\n",
    "        frame = av.VideoFrame.from_ndarray(image_array, format='gray')\n",
    "        frame.pict_type = 'NONE'\n",
    "        frame.time_base = stream.time_base\n",
    "        return frame\n",
    "\n",
    "    def export(self, loader: BaseLoader, output_path: str):\n",
    "        # Create an output container\n",
    "        i = -1\n",
    "        for traj_tensor in loader:\n",
    "            i += 1\n",
    "            trajectory = dict(traj_tensor)\n",
    "            output = av.open(f'{output_path}/output_{i}.mkv', mode='w')\n",
    "            # Define video streams (assuming images are 640x480 RGB)\n",
    "            video_stream_1 = output.add_stream('libx264', rate=1)\n",
    "            video_stream_1.width = 640\n",
    "            video_stream_1.height = 480\n",
    "            video_stream_1.pix_fmt = 'yuv420p'\n",
    "\n",
    "            video_stream_2 = output.add_stream('libx264', rate=1)\n",
    "            video_stream_2.width = 640\n",
    "            video_stream_2.height = 480\n",
    "            video_stream_2.pix_fmt = 'yuv420p'\n",
    "\n",
    "            # Define custom data stream for vectors\n",
    "            depth_stream = output.add_stream('libx264', rate=1)\n",
    "\n",
    "            data_stream = output.add_stream('rawvideo', rate=1)\n",
    "\n",
    "            ts = 0\n",
    "            # convert step data to stream\n",
    "            for step_tensor in trajectory[\"steps\"]:\n",
    "                step = dict(step_tensor)\n",
    "                obesrvation = step_tensor[\"observation\"].copy()\n",
    "                obesrvation.pop(\"image\")\n",
    "                obesrvation.pop(\"hand_image\")\n",
    "                obesrvation.pop(\"image_with_depth\")\n",
    "                non_image_data_step = step.copy()\n",
    "                non_image_data_step[\"observation\"] = obesrvation\n",
    "\n",
    "                non_image_data_bytes = pickle.dumps(non_image_data_step)\n",
    "                packet = av.Packet(non_image_data_bytes)\n",
    "                packet.stream = data_stream\n",
    "                packet.pts = ts\n",
    "                output.mux(packet)\n",
    "\n",
    "\n",
    "                image =np.array(step[\"observation\"][\"image\"])\n",
    "                # Create a frame from the numpy array\n",
    "                frame = self.create_frame(image, video_stream_1)\n",
    "                frame.pts = ts\n",
    "                packet = video_stream_1.encode(frame)\n",
    "                \n",
    "                output.mux(packet)\n",
    "\n",
    "                hand_image =np.array(step[\"observation\"][\"hand_image\"])\n",
    "                # Create a frame from the numpy array\n",
    "                frame = self.create_frame(hand_image, video_stream_2)\n",
    "                frame.pts = ts\n",
    "                packet = video_stream_2.encode(frame)\n",
    "                output.mux(packet)\n",
    "\n",
    "                # # Create a frame from the numpy array\n",
    "                frame = self.create_frame_depth(step[\"observation\"][\"image_with_depth\"], depth_stream)\n",
    "                # frame.pts = ts\n",
    "                # Encode the frame\n",
    "                packet = depth_stream.encode(frame)\n",
    "                # Write the packet to the output file\n",
    "                output.mux(packet)\n",
    "\n",
    "                ts += 1\n",
    "\n",
    "            \n",
    "            # Flush the remaining frames\n",
    "            for packet in video_stream_1.encode():\n",
    "                output.mux(packet)\n",
    "\n",
    "            for packet in video_stream_2.encode():\n",
    "                output.mux(packet)\n",
    "\n",
    "            for packet in depth_stream.encode():\n",
    "                output.mux(packet)\n",
    "            output.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b27ac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MKVLoader(BaseLoader):\n",
    "    def __init__(self, data_path):\n",
    "        super(MKVLoader, self).__init__(data_path)\n",
    "        self.files = [data_path + f for f in os.listdir(data_path) if f.endswith('.mkv')]\n",
    "        self.index = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return idx\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.index < len(self.files):\n",
    "            result = self.files[self.index]\n",
    "            self.index += 1\n",
    "            return self._parse_mkv_file(result)\n",
    "        else:\n",
    "            raise StopIteration\n",
    "    \n",
    "    def _parse_mkv_file(self, filename):\n",
    "        print(filename)\n",
    "        input_container = av.open(filename)\n",
    "        video_stream1 = input_container.streams.video[0] \n",
    "        video_stream1.thread_type = 'AUTO'\n",
    "        video_stream2 = input_container.streams.video[1] \n",
    "        video_stream2.thread_type = 'AUTO'\n",
    "        depth_stream = input_container.streams.video[2] \n",
    "        depth_stream.thread_type = 'AUTO'\n",
    "        data_stream = input_container.streams[3] \n",
    "\n",
    "        decoded_stream_1 = []\n",
    "        decoded_stream_2 = []\n",
    "        decoded_stream_depth = []\n",
    "        decoded_stream_data = []\n",
    "\n",
    "        pkt_counter = 0\n",
    "        for packet in input_container.demux(video_stream1, video_stream2, depth_stream, data_stream):\n",
    "            pkt_counter += 1\n",
    "            if packet.stream.index == video_stream1.index: \n",
    "                frame = packet.decode()\n",
    "                if frame:\n",
    "                    for f in frame:\n",
    "                        image = f.to_ndarray(format='rgb24')\n",
    "                        decoded_stream_1.append(image)\n",
    "            elif packet.stream.index == video_stream2.index:\n",
    "                frame = packet.decode()\n",
    "                if frame:\n",
    "                    for f in frame:\n",
    "                        image = f.to_ndarray(format='rgb24')\n",
    "                        decoded_stream_2.append(image)\n",
    "            elif packet.stream.index == depth_stream.index:\n",
    "                frame = packet.decode()\n",
    "                if frame:\n",
    "                    for f in frame:\n",
    "                        image = f.to_ndarray(format='gray')\n",
    "                        decoded_stream_depth.append(image)\n",
    "            elif packet.stream.index == data_stream.index:\n",
    "                packet_in_bytes = bytes(packet)\n",
    "                if packet_in_bytes:\n",
    "                    non_dict = pickle.loads(packet_in_bytes)\n",
    "                    decoded_stream_data.append(non_dict)\n",
    "            else:\n",
    "                print(\"Unknown stream\")\n",
    "        print(pkt_counter, len(decoded_stream_1), len(decoded_stream_2), len(decoded_stream_depth), len(decoded_stream_data))\n",
    "        input_container.close()\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89164adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_samples = 50\n",
    "def iterate_dataset(loader: BaseLoader, number_of_samples = 50):\n",
    "    for i, data in enumerate(loader): \n",
    "        list(dict(data)[\"steps\"])\n",
    "        if i == number_of_samples:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "caf5db32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I 2024-06-22 13:57:09,758 dataset_info.py:617] Load dataset info from /home/kych/datasets/berkeley_autolab_ur5/0.1.0\n",
      "I 2024-06-22 13:57:09,797 reader.py:261] Creating a tf.data.Dataset reading 26 files located in folders: /home/kych/datasets/berkeley_autolab_ur5/0.1.0.\n",
      "I 2024-06-22 13:57:09,915 logging_logger.py:49] Constructing tf.data.Dataset berkeley_autolab_ur5 for split train[:50], from /home/kych/datasets/berkeley_autolab_ur5/0.1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rtx_loader = RTXLoader(os.path.expanduser(\"~/datasets/berkeley_autolab_ur5/0.1.0\"), split = f'train[:{number_of_samples}]')\n",
    "iterate_dataset(rtx_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80867561",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exporter = MKVExporter()\n",
    "output_path = os.path.expanduser(\"~\") + \"/fog_x/examples/dataloader/mkv_output/\"\n",
    "%timeit exporter.export(rtx_loader, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcfc1bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_48.mkv\n",
      "424 105 105 105 105\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_10.mkv\n",
      "484 120 120 120 120\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_35.mkv\n",
      "488 121 121 121 121\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_14.mkv\n",
      "412 102 102 102 102\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_8.mkv\n",
      "340 84 84 84 84\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_49.mkv\n",
      "512 127 127 127 127\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_16.mkv\n",
      "436 108 108 108 108\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_12.mkv\n",
      "464 115 115 115 115\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_24.mkv\n",
      "328 81 81 81 81\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_11.mkv\n",
      "408 101 101 101 101\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_17.mkv\n",
      "388 96 96 96 96\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_4.mkv\n",
      "496 123 123 123 123\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_38.mkv\n",
      "428 106 106 106 106\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_0.mkv\n",
      "288 71 71 71 71\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_9.mkv\n",
      "392 97 97 97 97\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_37.mkv\n",
      "484 120 120 120 120\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_1.mkv\n",
      "308 76 76 76 76\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_2.mkv\n",
      "328 81 81 81 81\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_46.mkv\n",
      "344 85 85 85 85\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_45.mkv\n",
      "404 100 100 100 100\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_18.mkv\n",
      "300 74 74 74 74\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_20.mkv\n",
      "300 74 74 74 74\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_31.mkv\n",
      "392 97 97 97 97\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_43.mkv\n",
      "520 129 129 129 129\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_40.mkv\n",
      "460 114 114 114 114\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_30.mkv\n",
      "372 92 92 92 92\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_34.mkv\n",
      "480 119 119 119 119\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_42.mkv\n",
      "360 89 89 89 89\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_41.mkv\n",
      "360 89 89 89 89\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_47.mkv\n",
      "444 110 110 110 110\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_19.mkv\n",
      "304 75 75 75 75\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_26.mkv\n",
      "428 106 106 106 106\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_25.mkv\n",
      "432 107 107 107 107\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_7.mkv\n",
      "476 118 118 118 118\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_6.mkv\n",
      "444 110 110 110 110\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_33.mkv\n",
      "296 73 73 73 73\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_44.mkv\n",
      "432 107 107 107 107\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_27.mkv\n",
      "360 89 89 89 89\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_23.mkv\n",
      "428 106 106 106 106\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_29.mkv\n",
      "432 107 107 107 107\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_22.mkv\n",
      "312 77 77 77 77\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_21.mkv\n",
      "288 71 71 71 71\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_32.mkv\n",
      "388 96 96 96 96\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_36.mkv\n",
      "404 100 100 100 100\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_39.mkv\n",
      "496 123 123 123 123\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_13.mkv\n",
      "284 70 70 70 70\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_5.mkv\n",
      "416 103 103 103 103\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_15.mkv\n",
      "360 89 89 89 89\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_28.mkv\n",
      "328 81 81 81 81\n",
      "/home/kych/fog_x/examples/dataloader/mkv_output/output_3.mkv\n",
      "324 80 80 80 80\n"
     ]
    }
   ],
   "source": [
    "mkv_loader = MKVLoader(output_path)\n",
    "def iterate_dataset(loader: BaseLoader, number_of_samples = 50):\n",
    "    for i, data in enumerate(loader): \n",
    "        if i == number_of_samples:\n",
    "            break\n",
    "iterate_dataset(mkv_loader, number_of_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0822a45a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
